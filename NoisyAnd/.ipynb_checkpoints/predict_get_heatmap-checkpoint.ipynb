{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = {\n",
    "    'input_snippet_training_dir': '/projectnb/saenkog/awong1/dataset/kitti/processed3/training',\n",
    "    'input_snippet_validation_dir': '/projectnb/saenkog/awong1/dataset/kitti/processed3/validation',\n",
    "    'input_snippet_test_dir': '/projectnb/saenkog/awong1/dataset/kitti/processed3/testing',\n",
    "    'NUM_EPOCHS': 80,\n",
    "    'STEPS_PER_EPOCH': 500, # steps_per_epoch = ceil(num_samples / batch_size)\n",
    "    'INPUT_SHAPE': (128, 128, 1),\n",
    "    'SEED': 123,\n",
    "    'SAVE_DIRECTORY': 'conv_mil',\n",
    "    'MODEL_NAME': 'model35_kitti_input_model35_kitti_input__128x128_80epoch_0.001lr.h5',\n",
    "    'TRAIN': 0,\n",
    "    'VISUALIZE': 1,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'NUM_CLASSES': 2,\n",
    "    'heatmap_output_folder': 'heatmap_results/heatmap_128x128_model35'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 | tf test gpu avail: False\n",
      "c1 | device_lib.list_local_devices:  [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7572363606859792062\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15706402087014132029\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16230230821528299708\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11936232610869012374\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /projectnb/saenkog/awong1/MIL_CNN_KITTI_2/tf_cnnvis.py:25: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"c1 | tf test gpu avail:\", tf.test.is_gpu_available()) # True/False\n",
    "from tensorflow.python.client import device_lib\n",
    "print(\"c1 | device_lib.list_local_devices: \", device_lib.list_local_devices()) # list of DeviceAttributes\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D\n",
    "from keras.layers import Layer\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from datasets import Mnist\n",
    "from keras import optimizers\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_cnnvis import deconv_visualization\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Class\n",
    "class NoisyAnd(Layer):\n",
    "    \"\"\"Custom NoisyAND layer from the Deep MIL paper\"\"\"\n",
    "\n",
    "    def __init__(self, output_dim=flags['NUM_CLASSES'], **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(NoisyAnd, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.a = 10  # fixed, controls the slope of the activation\n",
    "        self.b = self.add_weight(name='b',\n",
    "                                 shape=(1, input_shape[3]),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        super(NoisyAnd, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        mean = tf.reduce_mean(x, axis=[1, 2])\n",
    "        res = (tf.nn.sigmoid(self.a * (mean - self.b)) - tf.nn.sigmoid(-self.a * self.b)) / (\n",
    "                tf.nn.sigmoid(self.a * (1 - self.b)) - tf.nn.sigmoid(-self.a * self.b))\n",
    "        return res\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[3]\n",
    "\n",
    "def define_model(input_shape, num_classes):\n",
    "    \"\"\"Define Deep FCN for MIL, layer-by-layer from original paper\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(1000, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(num_classes, (1, 1), activation='relu'))\n",
    "    model.add(NoisyAnd(num_classes))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def train_using_generator(train_generator, val_generator, epochs, steps_per_epoch, seed, input_shape, num_classes):\n",
    "    np.random.seed(seed)\n",
    "    model = define_model(input_shape, num_classes)\n",
    "    model.summary()\n",
    "    sgd = optimizers.SGD(lr=flags['LEARNING_RATE'])\n",
    "    print(\"Learning rate={}\".format(flags['LEARNING_RATE']))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs, verbose=1, shuffle=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize(sess, model, x_test):\n",
    "    \"\"\"Save png of deconvolution image from first image in test set\"\"\"\n",
    "    deconv_visualization(sess, {model.input: x_test[0:1, :, :, :]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_process_img(img_path, resize_dim=(128,128)):\n",
    "    img = cv2.imread(img_path, 0)\n",
    "    img = cv2.resize(img, resize_dim)\n",
    "    img = np.expand_dims(img, axis=4)\n",
    "    return img\n",
    "\n",
    "def build_dataset(dataset_path, output_orig=False):\n",
    "    X_has_pedestrian, X_no_pedestrian, y_has_pedestrian, y_no_pedestrian = [], [], [], []\n",
    "    for class_name in sorted(os.listdir(dataset_path)):\n",
    "        # Traverse image dir\n",
    "        for img_name in sorted(os.listdir(dataset_path + \"/\" + class_name)):\n",
    "            img_path = dataset_path + \"/\" + class_name + \"/\" + img_name\n",
    "            if output_orig:\n",
    "                img = cv2.imread(img_path)\n",
    "            else:\n",
    "                img = read_and_process_img(img_path, resize_dim=(128,128))\n",
    "            \n",
    "            if class_name == 'has_pedestrian':\n",
    "                X_has_pedestrian.append(img)\n",
    "                y_has_pedestrian.append(img)\n",
    "            else:\n",
    "                X_no_pedestrian.append(img)\n",
    "                y_no_pedestrian.append(img)\n",
    "    X_has_pedestrian, X_no_pedestrian, y_has_pedestrian, y_no_pedestrian = np.array(X_has_pedestrian), np.array(X_no_pedestrian), np.array(y_has_pedestrian), np.array(y_no_pedestrian)\n",
    "    return X_has_pedestrian, X_no_pedestrian, y_has_pedestrian, y_no_pedestrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img_arr, name_prefix, idx):\n",
    "    # Display Image\n",
    "    output = \"./heatmap/{}_orig_{}.jpeg\".format(name_prefix, idx)\n",
    "    cv2.imwrite(output, np.squeeze(img_arr))\n",
    "    \n",
    "    plt.imshow(mpimg.imread(output))\n",
    "    plt.show()\n",
    "\n",
    "def gen_heatmap(dataset, conv_layer_name, name_prefix, idx=0, disp_orig=False, disp_heat_mask=False, disp_heatmap=True):\n",
    "    img = np.array([dataset[idx]])\n",
    "    if disp_orig:\n",
    "        display_img(img, name_prefix, idx)\n",
    "\n",
    "    preds = model.predict(img)\n",
    "    # print(preds)\n",
    "    argmax = np.argmax(preds[0])\n",
    "    print(\"idx={}, Prediction={}\".format(idx, argmax))\n",
    "\n",
    "    output = model.output[:, argmax]\n",
    "    print(\"output\")\n",
    "    print(output)\n",
    "\n",
    "    # Get last layer\n",
    "    last_conv_layer = model.get_layer(conv_layer_name)\n",
    "    print(\"last_conv_layer\")\n",
    "    print(last_conv_layer)\n",
    "    print(last_conv_layer.output)\n",
    "\n",
    "    # Get gradient\n",
    "    grads = K.gradients(output, last_conv_layer.output)[0]\n",
    "    # print(grads)\n",
    "\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "    pooled_grads_value, conv_layer_output_value = iterate([img])\n",
    "    # print(conv_layer_output_value.shape)\n",
    "\n",
    "    for i in range(conv_layer_output_value.shape[2]):\n",
    "        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    if disp_heat_mask:\n",
    "        plt.imshow(heatmap)\n",
    "        plt.show()\n",
    "\n",
    "    # img = cv2.imread(img_path)\n",
    "    img_hm = dataset[idx]\n",
    "\n",
    "    heatmap = cv2.resize(heatmap, (img_hm.shape[1], img_hm.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap) # Flip because the COLORMAP_JET scale is flipped.\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    hif = .8\n",
    "    superimposed_img = heatmap * hif + img_hm\n",
    "\n",
    "    output = \"./{}/prediction_{}_{}_{}.jpeg\".format(flags['heatmap_output_folder'], argmax, name_prefix, idx)\n",
    "    cv2.imwrite(output, superimposed_img)\n",
    "\n",
    "    if disp_heatmap:\n",
    "        #Plot\n",
    "        plt.imshow(mpimg.imread(output))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr4/cs640/awong1/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr4/cs640/awong1/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "WARNING:tensorflow:From /usr4/cs640/awong1/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 60, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 1000)      1153000   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 2)         2002      \n",
      "_________________________________________________________________\n",
      "noisy_and_1 (NoisyAnd)       (None, 2)                 2         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 1,432,194\n",
      "Trainable params: 1,432,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(flags['SAVE_DIRECTORY'], flags['MODEL_NAME'])\n",
    "model = load_model(filepath, custom_objects={'NoisyAnd': NoisyAnd})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.6.9/install/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X_has_pedestrian, X_no_pedestrian, y_has_pedestrian, y_no_pedestrian = build_dataset(flags['input_snippet_test_dir'], output_orig=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate heat map (conv2d_6). Truth=has_pedestrian\n",
      "idx=0, Prediction=0\n",
      "output\n",
      "Tensor(\"strided_slice_52:0\", shape=(?,), dtype=float32)\n",
      "last_conv_layer\n",
      "<keras.layers.convolutional.Conv2D object at 0x2ab41f5797f0>\n",
      "Tensor(\"conv2d_6/Relu:0\", shape=(?, 10, 10, 1000), dtype=float32)\n",
      "Generate heat map (conv2d_6). Truth=no_pedestrian\n",
      "idx=0, Prediction=0\n",
      "output\n",
      "Tensor(\"strided_slice_54:0\", shape=(?,), dtype=float32)\n",
      "last_conv_layer\n",
      "<keras.layers.convolutional.Conv2D object at 0x2ab41f5797f0>\n",
      "Tensor(\"conv2d_6/Relu:0\", shape=(?, 10, 10, 1000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv_layer = 'conv2d_6'\n",
    "\n",
    "print(\"Generate heat map ({}). Truth={}\".format(conv_layer, 'has_pedestrian'))\n",
    "for i in range(20):\n",
    "    gen_heatmap(X_has_pedestrian, conv_layer, name_prefix=\"truth_has_pedestrian_heatmap\", idx=i, disp_orig=False, disp_heat_mask=False, disp_heatmap=False)\n",
    "    break\n",
    "    \n",
    "print(\"Generate heat map ({}). Truth={}\".format(conv_layer, 'no_pedestrian'))\n",
    "for i in range(20):\n",
    "    gen_heatmap(X_no_pedestrian, conv_layer, name_prefix=\"truth_no_pedestrian_heatmap\", idx=i, disp_orig=False, disp_heat_mask=False, disp_heatmap=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generate heatmap for each layer. (Truth={})\".format(\"has_pedestrian\"))\n",
    "for i in range (16):\n",
    "    for layer in model.layers:\n",
    "        if layer.name == \"noisy_and_1\" or layer.name == \"dense_1\":\n",
    "            continue\n",
    "        print(\"Heatmap layer({}), Img({})\".format(layer.name, i))\n",
    "        gen_heatmap(X_has_pedestrian, layer.name, \"truth_has_pedestrian_entire_model_heatmap_{}_{}\".format(i, layer.name), idx=i, disp_orig=False, disp_heat_mask=False, disp_heatmap=False)\n",
    "\n",
    "print(\"Generate heatmap for each layer. (Truth={})\".format(\"no_pedestrian\"))\n",
    "for i in range (16):\n",
    "    for layer in model.layers:\n",
    "        if layer.name == \"noisy_and_1\" or layer.name == \"dense_1\":\n",
    "            continue\n",
    "        print(\"Heatmap layer({}), Img({})\".format(layer.name, i))\n",
    "        gen_heatmap(X_has_pedestrian, layer.name, \"truth_no_pedestrian_entire_model_heatmap_{}_{}\".format(i, layer.name), idx=i, disp_orig=False, disp_heat_mask=False, disp_heatmap=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([[0, 255, 0], [0, 255, 0], [0, 255, 0]])\n",
    "# a = np.uint8(a)\n",
    "# b = cv2.applyColorMap(a, cv2.COLORMAP_HOT_r)\n",
    "# plt.imshow(b)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# heatmap = np.array([\n",
    "#     [0.5,0.5,0.5,0.5],\n",
    "#     [0,0.5,1.0,0.5],\n",
    "#     [0.5,0.5,0.5,0.5],\n",
    "# ])\n",
    "\n",
    "# heatmap = cv2.resize(heatmap, (400,300))\n",
    "# plt.imshow(heatmap)\n",
    "# plt.show()\n",
    "# heatmapshow = None\n",
    "# # heatmapshow = cv2.normalize(heatmap, heatmapshow, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "# heatmap = np.abs(255 - np.uint8(heatmap * 255))\n",
    "# print(heatmap)\n",
    "# heatmapshow = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "# plt.imshow(heatmapshow)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_output_layer(model, layer_name):\n",
    "#     # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "#     layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "#     layer = layer_dict[layer_name]\n",
    "#     return layer\n",
    "\n",
    "# def visualize_class_activation_map(model_path, img_path, output_path):\n",
    "#     model = load_model(model_path)\n",
    "#     original_img = cv2.imread(img_path, 1)\n",
    "#     width, height, _ = original_img.shape\n",
    "\n",
    "#     #Reshape to the network input shape (3, w, h).\n",
    "#     img = np.array([np.transpose(np.float32(original_img), (2, 0, 1))])\n",
    "\n",
    "#     #Get the 512 input weights to the softmax.\n",
    "#     class_weights = model.layers[-1].get_weights()[0]\n",
    "#     final_conv_layer = get_output_layer(model, \"conv5_3\")\n",
    "#     get_output = K.function([model.layers[0].input], \\\n",
    "#                 [final_conv_layer.output, \n",
    "#     model.layers[-1].output])\n",
    "#     [conv_outputs, predictions] = get_output([img])\n",
    "#     conv_outputs = conv_outputs[0, :, :, :]\n",
    "\n",
    "#     #Create the class activation map.\n",
    "#     cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])\n",
    "#     target_class = 1\n",
    "#     for i, w in enumerate(class_weights[:, target_class]):\n",
    "#             cam += w * conv_outputs[i, :, :]\n",
    "\n",
    "# # Execution\n",
    "# filepath = os.path.join(flags['SAVE_DIRECTORY'], flags['MODEL_NAME'])\n",
    "\n",
    "# with tf.Graph().as_default():\n",
    "#     with tf.Session() as sess:\n",
    "#         K.set_session(sess)\n",
    "\n",
    "#         # Load model\n",
    "#         print(\"Loading model...\")\n",
    "#         model = load_model(filepath, custom_objects={'NoisyAnd': NoisyAnd})\n",
    "#         print(\"Model Loaded\")\n",
    "        \n",
    "#         # Load test set\n",
    "#         X_test, y_test = build_dataset(flags['input_snippet_test_dir'], output_orig=False)\n",
    "#         X_test_orig, _ = build_dataset(flags['input_snippet_test_dir'], output_orig=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Execution\n",
    "# filepath = os.path.join(flags['SAVE_DIRECTORY'], flags['MODEL_NAME'])\n",
    "\n",
    "# with tf.Graph().as_default():\n",
    "#     with tf.Session() as sess:\n",
    "#         K.set_session(sess)\n",
    "\n",
    "#         # Load model\n",
    "#         print(\"Loading model...\")\n",
    "#         model = load_model(filepath, custom_objects={'NoisyAnd': NoisyAnd})\n",
    "#         print(\"Model Loaded\")\n",
    "        \n",
    "#         # Load test set\n",
    "#         X_test, y_test = build_dataset(flags['input_snippet_test_dir'], output_orig=False)\n",
    "#         X_test_orig, _ = build_dataset(flags['input_snippet_test_dir'], output_orig=True)\n",
    "        \n",
    "#         # Visualize with tf_cnnvis\n",
    "#         visualize(sess, model, X_test)\n",
    "\n",
    "# #         print(\"X_test shape={}, y_test shape={}\".format(X_test.shape, y_test.shape))\n",
    "# #         y_test_proc = (y_test != 'has_pedestrian')\n",
    "# #         print(\"y_test_proc shape:\", y_test_proc.shape)\n",
    "# #         # Evaluation\n",
    "# #         y_test_one_hot = keras.utils.to_categorical(y_test_proc, num_classes=flags['NUM_CLASSES'], dtype='int')\n",
    "# #         print(y_test_one_hot.shape)\n",
    "\n",
    "# #         eval_acc = model.evaluate(X_test, y_test_one_hot)\n",
    "# #         print(\"eval_acc (loss, precision): \", eval_acc)\n",
    "\n",
    "# #         # Prediction (Manual)\n",
    "# #         raw_preds = model.predict(X_test)\n",
    "# #         processed_preds = np.argmax(raw_preds, axis=1)\n",
    "\n",
    "# #         # Print\n",
    "# #         for i in range(len(X_test)):\n",
    "# #             print(\"Ground Truth =\", y_test[i], \", Prediction(has pedestrian)=\",  processed_preds[i]==0, \", Raw Prediction =\", raw_preds[i])\n",
    "# #             plt.imshow(X_test_orig[i])\n",
    "# #             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
